{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mudogruer/SLMs/blob/main/Llama-2/llama_2_13b_fine_tuning_sciq_20pc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T17:59:23.516510Z",
          "iopub.status.busy": "2024-02-22T17:59:23.515521Z",
          "iopub.status.idle": "2024-02-22T18:00:08.837109Z",
          "shell.execute_reply": "2024-02-22T18:00:08.836019Z",
          "shell.execute_reply.started": "2024-02-22T17:59:23.516471Z"
        },
        "id": "q-vyvjcEZB37",
        "outputId": "defa9f19-6d4e-476a-8346-620de152ef38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf 23.8.0 requires cubinlinker, which is not installed.\n",
            "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
            "cudf 23.8.0 requires ptxcompiler, which is not installed.\n",
            "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
            "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
            "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\n",
            "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.0 which is incompatible.\n",
            "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\n",
            "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\n",
            "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n",
            "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n",
            "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.0 which is incompatible.\n",
            "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\n",
            "cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\n",
            "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\n",
            "dask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\n",
            "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n",
            "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\n",
            "dask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\n",
            "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n",
            "gcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\n",
            "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\n",
            "raft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\n",
            "s3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U accelerate bitsandbytes peft datasets trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:00:17.249012Z",
          "iopub.status.busy": "2024-02-22T18:00:17.248640Z",
          "iopub.status.idle": "2024-02-22T18:00:25.265501Z",
          "shell.execute_reply": "2024-02-22T18:00:25.264601Z",
          "shell.execute_reply.started": "2024-02-22T18:00:17.248979Z"
        },
        "id": "4Of0OcB0ZB39",
        "outputId": "d622eac4-151a-4103-ddf7-d948d10a5219"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4.37.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:00:28.269770Z",
          "iopub.status.busy": "2024-02-22T18:00:28.269295Z",
          "iopub.status.idle": "2024-02-22T18:00:28.942624Z",
          "shell.execute_reply": "2024-02-22T18:00:28.941815Z",
          "shell.execute_reply.started": "2024-02-22T18:00:28.269743Z"
        },
        "id": "HezYdWOTZB3-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:00:29.222506Z",
          "iopub.status.busy": "2024-02-22T18:00:29.222178Z",
          "iopub.status.idle": "2024-02-22T18:00:29.226633Z",
          "shell.execute_reply": "2024-02-22T18:00:29.225709Z",
          "shell.execute_reply.started": "2024-02-22T18:00:29.222480Z"
        },
        "id": "lSWb97K-ZB3-"
      },
      "outputs": [],
      "source": [
        "base_model = \"meta-llama/Llama-2-13b-chat-hf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:00:31.137729Z",
          "iopub.status.busy": "2024-02-22T18:00:31.137349Z",
          "iopub.status.idle": "2024-02-22T18:00:31.166032Z",
          "shell.execute_reply": "2024-02-22T18:00:31.165239Z",
          "shell.execute_reply.started": "2024-02-22T18:00:31.137703Z"
        },
        "id": "gvMyiW3PZB3_",
        "outputId": "6147a7a8-dd45-4746-b47d-ee8bac38525d",
        "colab": {
          "referenced_widgets": [
            "a310614cdf7e46f09b107d43a552632f"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a310614cdf7e46f09b107d43a552632f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:00:40.393504Z",
          "iopub.status.busy": "2024-02-22T18:00:40.393115Z",
          "iopub.status.idle": "2024-02-22T18:00:41.398883Z",
          "shell.execute_reply": "2024-02-22T18:00:41.397992Z",
          "shell.execute_reply.started": "2024-02-22T18:00:40.393474Z"
        },
        "id": "m9pzKtokZB3_",
        "outputId": "14692e33-9a6e-412d-810b-86a6cfb74203",
        "colab": {
          "referenced_widgets": [
            "bb820cc106a44cb09df55e509e8d7d8a",
            "4681442fceff4715aba375fcd760f5f7",
            "253c83d168fe43af889e981d4e446125",
            "ee89c9ee4d6a4cb1bf5cb74247734e25"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb820cc106a44cb09df55e509e8d7d8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4681442fceff4715aba375fcd760f5f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "253c83d168fe43af889e981d4e446125",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee89c9ee4d6a4cb1bf5cb74247734e25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model,\n",
        "    padding_side = \"right\",\n",
        "    add_eos_token = True,\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_bos_token, tokenizer.add_eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:00:44.875596Z",
          "iopub.status.busy": "2024-02-22T18:00:44.875183Z",
          "iopub.status.idle": "2024-02-22T18:00:44.882121Z",
          "shell.execute_reply": "2024-02-22T18:00:44.880964Z",
          "shell.execute_reply.started": "2024-02-22T18:00:44.875564Z"
        },
        "id": "PPiOG6UDZB4A",
        "outputId": "3f6a955e-5638-4c18-a9c7-067a49221b2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaTokenizerFast(name_or_path='meta-llama/Llama-2-13b-chat-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:00:51.006302Z",
          "iopub.status.busy": "2024-02-22T18:00:51.005926Z",
          "iopub.status.idle": "2024-02-22T18:00:51.016869Z",
          "shell.execute_reply": "2024-02-22T18:00:51.015787Z",
          "shell.execute_reply.started": "2024-02-22T18:00:51.006273Z"
        },
        "id": "A4x2e3W0ZB4A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:00:52.994840Z",
          "iopub.status.busy": "2024-02-22T18:00:52.994486Z",
          "iopub.status.idle": "2024-02-22T18:05:25.515724Z",
          "shell.execute_reply": "2024-02-22T18:05:25.514775Z",
          "shell.execute_reply.started": "2024-02-22T18:00:52.994813Z"
        },
        "id": "qngQLjAbZB4B",
        "outputId": "508cd045-47ca-4bfb-9718-20f357f3f060",
        "colab": {
          "referenced_widgets": [
            "c91ba680ea114718a229e34311445246",
            "0b1a62230a534308a29fb7b4609fe7a0",
            "b864484e17b04808a724907b3f4c1418",
            "d3834420677547ebb1706662a5446f64",
            "a415655432c7453ba5f528c959cf50c1",
            "8bb7765e2c80488aa1ba49d0a001624b",
            "672793f0ff6f49f5ad0638e2e980ae95",
            "e65cd9cc66384dc29089fbf9c10e9b27"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c91ba680ea114718a229e34311445246",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b1a62230a534308a29fb7b4609fe7a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b864484e17b04808a724907b3f4c1418",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3834420677547ebb1706662a5446f64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a415655432c7453ba5f528c959cf50c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bb7765e2c80488aa1ba49d0a001624b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "672793f0ff6f49f5ad0638e2e980ae95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e65cd9cc66384dc29089fbf9c10e9b27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    load_in_4bit=True,\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:05:44.388003Z",
          "iopub.status.busy": "2024-02-22T18:05:44.387193Z",
          "iopub.status.idle": "2024-02-22T18:05:46.137980Z",
          "shell.execute_reply": "2024-02-22T18:05:46.137184Z",
          "shell.execute_reply.started": "2024-02-22T18:05:44.387970Z"
        },
        "id": "hpgsfDF6ZB4B"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"sciq\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:06:05.561169Z",
          "iopub.status.busy": "2024-02-22T18:06:05.560223Z",
          "iopub.status.idle": "2024-02-22T18:06:13.248236Z",
          "shell.execute_reply": "2024-02-22T18:06:13.247484Z",
          "shell.execute_reply.started": "2024-02-22T18:06:05.561135Z"
        },
        "id": "w1yNaNNUZB4B",
        "outputId": "ed1cbe55-a140-4721-8e2b-115c44dd5393",
        "colab": {
          "referenced_widgets": [
            "c233ea1999ae454b848d4811ba50b320",
            "00be9d2ec54e4a67b8786fca34143514",
            "1eeddc9d6bbd4ba0befc4e543b8856f2",
            "5bbf48f13bd34a9384c0bb3065791e60",
            "f4f6b769999a41858e097e9885e30de3",
            "3f57be0444174771a9b5e646b5b8b145",
            "e81ecda785ba4cc0926da493d0f27845"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c233ea1999ae454b848d4811ba50b320",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00be9d2ec54e4a67b8786fca34143514",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/3.99M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1eeddc9d6bbd4ba0befc4e543b8856f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/339k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bbf48f13bd34a9384c0bb3065791e60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/343k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4f6b769999a41858e097e9885e30de3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/11679 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f57be0444174771a9b5e646b5b8b145",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e81ecda785ba4cc0926da493d0f27845",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset = load_dataset(dataset_name, split = \"train[0:20%]\")\n",
        "eval_dataset = load_dataset(dataset_name, split=\"validation[0:20%]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:06:25.827218Z",
          "iopub.status.busy": "2024-02-22T18:06:25.826424Z",
          "iopub.status.idle": "2024-02-22T18:06:25.902494Z",
          "shell.execute_reply": "2024-02-22T18:06:25.901584Z",
          "shell.execute_reply.started": "2024-02-22T18:06:25.827174Z"
        },
        "id": "NcYrxWWqZB4C",
        "outputId": "488d94a8-b08b-49dd-8030-0276991b7410"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>distractor3</th>\n",
              "      <th>distractor1</th>\n",
              "      <th>distractor2</th>\n",
              "      <th>correct_answer</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What type of organism is commonly used in prep...</td>\n",
              "      <td>viruses</td>\n",
              "      <td>protozoa</td>\n",
              "      <td>gymnosperms</td>\n",
              "      <td>mesophilic organisms</td>\n",
              "      <td>Mesophiles grow best in moderate temperature, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What phenomenon makes global winds blow northe...</td>\n",
              "      <td>tropical effect</td>\n",
              "      <td>muon effect</td>\n",
              "      <td>centrifugal effect</td>\n",
              "      <td>coriolis effect</td>\n",
              "      <td>Without Coriolis Effect the global winds would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Changes from a less-ordered state to a more-or...</td>\n",
              "      <td>endothermic</td>\n",
              "      <td>unbalanced</td>\n",
              "      <td>reactive</td>\n",
              "      <td>exothermic</td>\n",
              "      <td>Summary Changes of state are examples of phase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the least dangerous radioactive decay?</td>\n",
              "      <td>zeta decay</td>\n",
              "      <td>beta decay</td>\n",
              "      <td>gamma decay</td>\n",
              "      <td>alpha decay</td>\n",
              "      <td>All radioactive decay is dangerous to living t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kilauea in hawaii is the world’s most continuo...</td>\n",
              "      <td>magma</td>\n",
              "      <td>greenhouse gases</td>\n",
              "      <td>carbon and smog</td>\n",
              "      <td>smoke and ash</td>\n",
              "      <td>Example 3.5 Calculating Projectile Motion: Hot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>When a meteoroid reaches earth, what is the re...</td>\n",
              "      <td>orbit</td>\n",
              "      <td>comet</td>\n",
              "      <td>meteor</td>\n",
              "      <td>meteorite</td>\n",
              "      <td>Meteoroids are smaller than asteroids, ranging...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What kind of a reaction occurs when a substanc...</td>\n",
              "      <td>nitrogen reaction</td>\n",
              "      <td>invention reaction</td>\n",
              "      <td>Fluid Reaction</td>\n",
              "      <td>combustion reaction</td>\n",
              "      <td>A combustion reaction occurs when a substance ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Organisms categorized by what species descript...</td>\n",
              "      <td>species complex</td>\n",
              "      <td>surface species</td>\n",
              "      <td>fitting species</td>\n",
              "      <td>ring species</td>\n",
              "      <td>Ring species Ring species demonstrate a versio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Alpha emission is a type of what?</td>\n",
              "      <td>light</td>\n",
              "      <td>radiation</td>\n",
              "      <td>heat</td>\n",
              "      <td>radioactivity</td>\n",
              "      <td>One type of radioactivity is alpha emission. W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What is the stored food in a seed called?</td>\n",
              "      <td>larval</td>\n",
              "      <td>pollin</td>\n",
              "      <td>membrane</td>\n",
              "      <td>endosperm</td>\n",
              "      <td>The stored food in a seed is called endosperm ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question        distractor3  \\\n",
              "0  What type of organism is commonly used in prep...            viruses   \n",
              "1  What phenomenon makes global winds blow northe...    tropical effect   \n",
              "2  Changes from a less-ordered state to a more-or...        endothermic   \n",
              "3     What is the least dangerous radioactive decay?         zeta decay   \n",
              "4  Kilauea in hawaii is the world’s most continuo...              magma   \n",
              "5  When a meteoroid reaches earth, what is the re...              orbit   \n",
              "6  What kind of a reaction occurs when a substanc...  nitrogen reaction   \n",
              "7  Organisms categorized by what species descript...    species complex   \n",
              "8                  Alpha emission is a type of what?              light   \n",
              "9          What is the stored food in a seed called?             larval   \n",
              "\n",
              "          distractor1         distractor2        correct_answer  \\\n",
              "0            protozoa         gymnosperms  mesophilic organisms   \n",
              "1         muon effect  centrifugal effect       coriolis effect   \n",
              "2          unbalanced            reactive            exothermic   \n",
              "3          beta decay         gamma decay           alpha decay   \n",
              "4    greenhouse gases     carbon and smog         smoke and ash   \n",
              "5               comet              meteor             meteorite   \n",
              "6  invention reaction      Fluid Reaction   combustion reaction   \n",
              "7     surface species     fitting species          ring species   \n",
              "8           radiation                heat         radioactivity   \n",
              "9              pollin            membrane             endosperm   \n",
              "\n",
              "                                             support  \n",
              "0  Mesophiles grow best in moderate temperature, ...  \n",
              "1  Without Coriolis Effect the global winds would...  \n",
              "2  Summary Changes of state are examples of phase...  \n",
              "3  All radioactive decay is dangerous to living t...  \n",
              "4  Example 3.5 Calculating Projectile Motion: Hot...  \n",
              "5  Meteoroids are smaller than asteroids, ranging...  \n",
              "6  A combustion reaction occurs when a substance ...  \n",
              "7  Ring species Ring species demonstrate a versio...  \n",
              "8  One type of radioactivity is alpha emission. W...  \n",
              "9  The stored food in a seed is called endosperm ...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.to_pandas().head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:06:30.857596Z",
          "iopub.status.busy": "2024-02-22T18:06:30.856882Z",
          "iopub.status.idle": "2024-02-22T18:06:30.873963Z",
          "shell.execute_reply": "2024-02-22T18:06:30.873173Z",
          "shell.execute_reply.started": "2024-02-22T18:06:30.857567Z"
        },
        "id": "fKVrX7TOZB4C",
        "outputId": "65627a88-0b5f-47a0-f0ba-e4f03d282886"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "question          object\n",
              "distractor3       object\n",
              "distractor1       object\n",
              "distractor2       object\n",
              "correct_answer    object\n",
              "support           object\n",
              "dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.to_pandas().dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:06:33.397518Z",
          "iopub.status.busy": "2024-02-22T18:06:33.397121Z",
          "iopub.status.idle": "2024-02-22T18:06:33.402766Z",
          "shell.execute_reply": "2024-02-22T18:06:33.401842Z",
          "shell.execute_reply.started": "2024-02-22T18:06:33.397490Z"
        },
        "id": "ASak7zL0ZB4C"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(sample):\n",
        "    full_prompt =f\"\"\"<s>[INST]{sample['question']}\n",
        "    {f\"Here is some info: {sample['support']}\" if len(sample[\"support\"]) > 0 else None}\n",
        "    [/INST] {sample['correct_answer']}</s>\"\"\"\n",
        "    return {\"text\": full_prompt}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:06:36.922410Z",
          "iopub.status.busy": "2024-02-22T18:06:36.922028Z",
          "iopub.status.idle": "2024-02-22T18:06:36.930324Z",
          "shell.execute_reply": "2024-02-22T18:06:36.929368Z",
          "shell.execute_reply.started": "2024-02-22T18:06:36.922382Z"
        },
        "id": "-NBNN6lpZB4D",
        "outputId": "08e25f1f-37d9-47d5-d6ca-e5cb3d328aa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': '<s>[INST]What type of organism is commonly used in preparation of foods such as cheese and yogurt?\\n    Here is some info: Mesophiles grow best in moderate temperature, typically between 25°C and 40°C (77°F and 104°F). Mesophiles are often found living in or on the bodies of humans or other animals. The optimal growth temperature of many pathogenic mesophiles is 37°C (98°F), the normal human body temperature. Mesophilic organisms have important uses in food preparation, including cheese, yogurt, beer and wine.\\n    [/INST] mesophilic organisms</s>'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_prompt(train_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:06:39.541963Z",
          "iopub.status.busy": "2024-02-22T18:06:39.541080Z",
          "iopub.status.idle": "2024-02-22T18:06:39.855241Z",
          "shell.execute_reply": "2024-02-22T18:06:39.854334Z",
          "shell.execute_reply.started": "2024-02-22T18:06:39.541927Z"
        },
        "id": "0-T1MDpPZB4D",
        "outputId": "8979b26a-855c-4321-8c57-9bbeab7b54a6",
        "colab": {
          "referenced_widgets": [
            "39ac4a882ea049ccbe2da1ec845e11ad",
            "ee55bf1c5d1a4f82a7f9e1dcea4bdc16"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39ac4a882ea049ccbe2da1ec845e11ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2336 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee55bf1c5d1a4f82a7f9e1dcea4bdc16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generated_train_dataset = train_dataset.map(\n",
        "    generate_prompt, remove_columns=list(train_dataset.features))\n",
        "generated_val_dataset = eval_dataset.map(\n",
        "    generate_prompt, remove_columns=list(eval_dataset.features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:06:49.317040Z",
          "iopub.status.busy": "2024-02-22T18:06:49.316136Z",
          "iopub.status.idle": "2024-02-22T18:06:49.322965Z",
          "shell.execute_reply": "2024-02-22T18:06:49.321929Z",
          "shell.execute_reply.started": "2024-02-22T18:06:49.317008Z"
        },
        "id": "76ZAUftVZB4D",
        "outputId": "59705a5c-be2a-4e51-c74f-e551d5d70ae8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<s>[INST]When a meteoroid reaches earth, what is the remaining object called?\\n    Here is some info: Meteoroids are smaller than asteroids, ranging from the size of boulders to the size of sand grains. When meteoroids enter Earth’s atmosphere, they vaporize, creating a trail of glowing gas called a meteor. If any of the meteoroid reaches Earth, the remaining object is called a meteorite.\\n    [/INST] meteorite</s>'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_train_dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:07:55.515285Z",
          "iopub.status.busy": "2024-02-22T18:07:55.514620Z",
          "iopub.status.idle": "2024-02-22T18:07:55.618722Z",
          "shell.execute_reply": "2024-02-22T18:07:55.617956Z",
          "shell.execute_reply.started": "2024-02-22T18:07:55.515250Z"
        },
        "id": "Nw4UnJ4KZB4D"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:07:58.767323Z",
          "iopub.status.busy": "2024-02-22T18:07:58.766929Z",
          "iopub.status.idle": "2024-02-22T18:07:58.773990Z",
          "shell.execute_reply": "2024-02-22T18:07:58.772258Z",
          "shell.execute_reply.started": "2024-02-22T18:07:58.767291Z"
        },
        "id": "kD8mSr3UZB4D"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:08:05.880930Z",
          "iopub.status.busy": "2024-02-22T18:08:05.879875Z",
          "iopub.status.idle": "2024-02-22T18:08:05.885819Z",
          "shell.execute_reply": "2024-02-22T18:08:05.884888Z",
          "shell.execute_reply.started": "2024-02-22T18:08:05.880897Z"
        },
        "id": "T_PcpIQqZB4E"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:08:10.502546Z",
          "iopub.status.busy": "2024-02-22T18:08:10.502121Z",
          "iopub.status.idle": "2024-02-22T18:08:11.450310Z",
          "shell.execute_reply": "2024-02-22T18:08:11.449354Z",
          "shell.execute_reply.started": "2024-02-22T18:08:10.502515Z"
        },
        "id": "090SFrCfZB4E",
        "outputId": "640b60b5-45c4-42f8-98bf-f18cbb90f8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 31590400 || all params: 6703569920 || trainable%: 0.4712474155859927\n"
          ]
        }
      ],
      "source": [
        "from peft import get_peft_model\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:08:18.313344Z",
          "iopub.status.busy": "2024-02-22T18:08:18.312923Z",
          "iopub.status.idle": "2024-02-22T18:08:18.339006Z",
          "shell.execute_reply": "2024-02-22T18:08:18.338241Z",
          "shell.execute_reply.started": "2024-02-22T18:08:18.313312Z"
        },
        "id": "UD6vsacbZB4E"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=25,\n",
        "    logging_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    max_steps=50,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    do_eval=True,\n",
        "    report_to=\"none\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:08:22.087441Z",
          "iopub.status.busy": "2024-02-22T18:08:22.086772Z",
          "iopub.status.idle": "2024-02-22T18:08:41.414740Z",
          "shell.execute_reply": "2024-02-22T18:08:41.413968Z",
          "shell.execute_reply.started": "2024-02-22T18:08:22.087411Z"
        },
        "id": "1rqbljlFZB4E",
        "outputId": "84d9a3e8-ba96-4a56-9b2d-0b27063eef66",
        "colab": {
          "referenced_widgets": [
            "5d01504803ad48488e084cd42500e2df",
            "214a44e08e284f2ab4cd52cde65625ac"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-22 18:08:26.897121: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-22 18:08:26.897256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-22 18:08:27.180935: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:225: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d01504803ad48488e084cd42500e2df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2336 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "214a44e08e284f2ab4cd52cde65625ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "# Setting sft parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    train_dataset=generated_train_dataset,\n",
        "    eval_dataset=generated_val_dataset,\n",
        "    peft_config=lora_config,\n",
        "    dataset_text_field=\"text\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:09:37.431004Z",
          "iopub.status.busy": "2024-02-22T18:09:37.430129Z",
          "iopub.status.idle": "2024-02-22T18:47:54.363940Z",
          "shell.execute_reply": "2024-02-22T18:47:54.363061Z",
          "shell.execute_reply.started": "2024-02-22T18:09:37.430972Z"
        },
        "id": "FXgxV6csZB4E",
        "outputId": "8b4ff955-23ee-4a3a-91e4-479ece5859c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 37:39, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.836500</td>\n",
              "      <td>1.456741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.381800</td>\n",
              "      <td>1.381411</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50, training_loss=1.6091473388671875, metrics={'train_runtime': 2296.5159, 'train_samples_per_second': 0.087, 'train_steps_per_second': 0.022, 'total_flos': 3735217579622400.0, 'train_loss': 1.6091473388671875, 'epoch': 0.09})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config.use_cache = False\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T18:50:18.028320Z",
          "iopub.status.busy": "2024-02-22T18:50:18.027048Z",
          "iopub.status.idle": "2024-02-22T18:50:41.945614Z",
          "shell.execute_reply": "2024-02-22T18:50:41.944646Z",
          "shell.execute_reply.started": "2024-02-22T18:50:18.028269Z"
        },
        "id": "4CHHpxoEZB4E",
        "outputId": "0ef3995b-cdc8-407c-aeaf-206da4e5e1c5",
        "colab": {
          "referenced_widgets": [
            "891968de011b45079ebfc997862a1e3d"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "891968de011b45079ebfc997862a1e3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/782M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/mudogruer/Llama-2-13b-hf-SciQ-20pc/commit/2e53a205904754f23df5d9ff2800c0851597b87b', commit_message='Upload model', commit_description='', oid='2e53a205904754f23df5d9ff2800c0851597b87b', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_finetuned_model = \"Llama-2-13b-hf-SciQ-20pc\"\n",
        "\n",
        "trainer.model.push_to_hub(my_finetuned_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLITd5FcZB4F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}