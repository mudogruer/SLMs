{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mudogruer/SLMs/blob/main/phi-2/phi_2_fine_tuning_sciq_20pc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:50:33.628218Z",
          "iopub.status.busy": "2024-02-21T12:50:33.627867Z",
          "iopub.status.idle": "2024-02-21T12:51:07.527927Z",
          "shell.execute_reply": "2024-02-21T12:51:07.526830Z",
          "shell.execute_reply.started": "2024-02-21T12:50:33.628189Z"
        },
        "id": "8N-kHcpAU4me",
        "outputId": "493fe49f-1731-46b9-f5c1-edded7a4c1bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf 23.8.0 requires cubinlinker, which is not installed.\n",
            "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
            "cudf 23.8.0 requires ptxcompiler, which is not installed.\n",
            "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
            "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
            "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\n",
            "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.0 which is incompatible.\n",
            "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\n",
            "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\n",
            "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n",
            "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n",
            "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.0 which is incompatible.\n",
            "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\n",
            "cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\n",
            "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\n",
            "dask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\n",
            "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n",
            "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\n",
            "dask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\n",
            "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n",
            "gcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\n",
            "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\n",
            "raft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\n",
            "s3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U accelerate bitsandbytes peft datasets trl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AerpdklzU4mg"
      },
      "source": [
        "### This code involved Microsoft Phi model tine tuning with 20% of Sciq Dataset using with LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:52:00.331433Z",
          "iopub.status.busy": "2024-02-21T12:52:00.331053Z",
          "iopub.status.idle": "2024-02-21T12:52:05.896141Z",
          "shell.execute_reply": "2024-02-21T12:52:05.895118Z",
          "shell.execute_reply.started": "2024-02-21T12:52:00.331384Z"
        },
        "id": "UnlKj9YWU4mh",
        "outputId": "e8f19a0d-e736-4ca0-85bc-2b22f04f5e64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4.37.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:52:08.298673Z",
          "iopub.status.busy": "2024-02-21T12:52:08.298194Z",
          "iopub.status.idle": "2024-02-21T12:52:08.737625Z",
          "shell.execute_reply": "2024-02-21T12:52:08.736650Z",
          "shell.execute_reply.started": "2024-02-21T12:52:08.298644Z"
        },
        "id": "36zlgXG1U4mh"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:52:10.806039Z",
          "iopub.status.busy": "2024-02-21T12:52:10.805679Z",
          "iopub.status.idle": "2024-02-21T12:52:10.810471Z",
          "shell.execute_reply": "2024-02-21T12:52:10.809495Z",
          "shell.execute_reply.started": "2024-02-21T12:52:10.806011Z"
        },
        "id": "wR-pPzkAU4mj"
      },
      "outputs": [],
      "source": [
        "base_model = \"microsoft/phi-2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-31T12:03:24.614974Z",
          "iopub.status.busy": "2024-01-31T12:03:24.614065Z",
          "iopub.status.idle": "2024-01-31T12:03:24.641573Z",
          "shell.execute_reply": "2024-01-31T12:03:24.640662Z",
          "shell.execute_reply.started": "2024-01-31T12:03:24.614941Z"
        },
        "id": "GaULlir_U4mj",
        "outputId": "40482a1f-3987-44d6-c433-61a51536e534",
        "colab": {
          "referenced_widgets": [
            "fbc5c7be10234d59bdc50c51608e8605"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbc5c7be10234d59bdc50c51608e8605",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from huggingface_hub import login\n",
        "# login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:52:28.853646Z",
          "iopub.status.busy": "2024-02-21T12:52:28.853286Z",
          "iopub.status.idle": "2024-02-21T12:52:28.999827Z",
          "shell.execute_reply": "2024-02-21T12:52:28.998926Z",
          "shell.execute_reply.started": "2024-02-21T12:52:28.853618Z"
        },
        "id": "Vf7jOyZFU4mk",
        "outputId": "21046751-c985-42a4-a2e6-eee98f19c9de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model,\n",
        "    padding_side = \"right\",\n",
        "    add_eos_token = True,\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:52:31.847013Z",
          "iopub.status.busy": "2024-02-21T12:52:31.846589Z",
          "iopub.status.idle": "2024-02-21T12:52:31.853353Z",
          "shell.execute_reply": "2024-02-21T12:52:31.852397Z",
          "shell.execute_reply.started": "2024-02-21T12:52:31.846982Z"
        },
        "id": "eIyb8OQ1U4mk",
        "outputId": "3197ad7d-6120-49c5-9fea-03b70f9b7597"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CodeGenTokenizerFast(name_or_path='microsoft/phi-2', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t50257: AddedToken(\"                               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50258: AddedToken(\"                              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50259: AddedToken(\"                             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50260: AddedToken(\"                            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50261: AddedToken(\"                           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50262: AddedToken(\"                          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50263: AddedToken(\"                         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50264: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50265: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50266: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50267: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50268: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50269: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50270: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50271: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50272: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50273: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50274: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50275: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50276: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50277: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50278: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50279: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50280: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50281: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50282: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50283: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50284: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50285: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50286: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50287: AddedToken(\"\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50288: AddedToken(\"\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50289: AddedToken(\"\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50290: AddedToken(\"\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50291: AddedToken(\"\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50292: AddedToken(\"\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50293: AddedToken(\"\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "\t50294: AddedToken(\"\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:52:44.812779Z",
          "iopub.status.busy": "2024-02-21T12:52:44.812412Z",
          "iopub.status.idle": "2024-02-21T12:52:44.822504Z",
          "shell.execute_reply": "2024-02-21T12:52:44.821648Z",
          "shell.execute_reply.started": "2024-02-21T12:52:44.812745Z"
        },
        "id": "JOV1KWE6U4ml"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:52:51.160852Z",
          "iopub.status.busy": "2024-02-21T12:52:51.160021Z",
          "iopub.status.idle": "2024-02-21T12:53:30.619031Z",
          "shell.execute_reply": "2024-02-21T12:53:30.618086Z",
          "shell.execute_reply.started": "2024-02-21T12:52:51.160816Z"
        },
        "id": "vylDIAfzU4mm",
        "outputId": "03ad8a2a-6b3e-4d5b-cdbc-a7390e5015c7",
        "colab": {
          "referenced_widgets": [
            "dd34fbc9318145eca1098ececb6e307a",
            "40b6809a01634f38812d2d3494414a08",
            "907cabbb564f4736ac5e7e947d59668d",
            "20196ec0cbf54751ac0d60f2c4fe2f44",
            "7e32b540adb24916b744a6cea4e3d1e6",
            "315e88ea557d447eab9e1e4929868746",
            "9ff886b3c2a24a43a9fc7dc4da048f3c"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd34fbc9318145eca1098ececb6e307a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/863 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40b6809a01634f38812d2d3494414a08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "907cabbb564f4736ac5e7e947d59668d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20196ec0cbf54751ac0d60f2c4fe2f44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e32b540adb24916b744a6cea4e3d1e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "315e88ea557d447eab9e1e4929868746",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ff886b3c2a24a43a9fc7dc4da048f3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    load_in_4bit=True,\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:53:46.762330Z",
          "iopub.status.busy": "2024-02-21T12:53:46.761909Z",
          "iopub.status.idle": "2024-02-21T12:53:46.771641Z",
          "shell.execute_reply": "2024-02-21T12:53:46.770632Z",
          "shell.execute_reply.started": "2024-02-21T12:53:46.762298Z"
        },
        "id": "XhvfOJGeU4mn",
        "outputId": "77fc8e6f-c79e-4e2d-d8ec-191e77566da3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PhiForCausalLM(\n",
              "  (model): PhiModel(\n",
              "    (embed_tokens): Embedding(51200, 2560)\n",
              "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x PhiDecoderLayer(\n",
              "        (self_attn): PhiAttention(\n",
              "          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "          (rotary_emb): PhiRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): PhiMLP(\n",
              "          (activation_fn): NewGELUActivation()\n",
              "          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
              "          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
              "        )\n",
              "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:53:52.200319Z",
          "iopub.status.busy": "2024-02-21T12:53:52.199300Z",
          "iopub.status.idle": "2024-02-21T12:53:52.886053Z",
          "shell.execute_reply": "2024-02-21T12:53:52.885146Z",
          "shell.execute_reply.started": "2024-02-21T12:53:52.200278Z"
        },
        "id": "L-5TeRuOU4mo"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"sciq\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:57:49.183342Z",
          "iopub.status.busy": "2024-02-21T12:57:49.182302Z",
          "iopub.status.idle": "2024-02-21T12:57:52.174433Z",
          "shell.execute_reply": "2024-02-21T12:57:52.173618Z",
          "shell.execute_reply.started": "2024-02-21T12:57:49.183299Z"
        },
        "id": "ahl9x9Y_U4mo"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:58:21.204267Z",
          "iopub.status.busy": "2024-02-21T12:58:21.203871Z",
          "iopub.status.idle": "2024-02-21T12:58:26.803059Z",
          "shell.execute_reply": "2024-02-21T12:58:26.802066Z",
          "shell.execute_reply.started": "2024-02-21T12:58:21.204222Z"
        },
        "id": "B7DzQXhHU4mo"
      },
      "outputs": [],
      "source": [
        "train_dataset = load_dataset(dataset_name, split ='train[:20%]')\n",
        "eval_dataset = load_dataset(dataset_name, split='validation[:20%]')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:58:34.071771Z",
          "iopub.status.busy": "2024-02-21T12:58:34.070931Z",
          "iopub.status.idle": "2024-02-21T12:58:34.108992Z",
          "shell.execute_reply": "2024-02-21T12:58:34.108125Z",
          "shell.execute_reply.started": "2024-02-21T12:58:34.071729Z"
        },
        "id": "Gr7uL2v_U4mo",
        "outputId": "ba9c2d7c-07bc-401d-a178-a080885c00c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>distractor3</th>\n",
              "      <th>distractor1</th>\n",
              "      <th>distractor2</th>\n",
              "      <th>correct_answer</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What type of organism is commonly used in prep...</td>\n",
              "      <td>viruses</td>\n",
              "      <td>protozoa</td>\n",
              "      <td>gymnosperms</td>\n",
              "      <td>mesophilic organisms</td>\n",
              "      <td>Mesophiles grow best in moderate temperature, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What phenomenon makes global winds blow northe...</td>\n",
              "      <td>tropical effect</td>\n",
              "      <td>muon effect</td>\n",
              "      <td>centrifugal effect</td>\n",
              "      <td>coriolis effect</td>\n",
              "      <td>Without Coriolis Effect the global winds would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Changes from a less-ordered state to a more-or...</td>\n",
              "      <td>endothermic</td>\n",
              "      <td>unbalanced</td>\n",
              "      <td>reactive</td>\n",
              "      <td>exothermic</td>\n",
              "      <td>Summary Changes of state are examples of phase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the least dangerous radioactive decay?</td>\n",
              "      <td>zeta decay</td>\n",
              "      <td>beta decay</td>\n",
              "      <td>gamma decay</td>\n",
              "      <td>alpha decay</td>\n",
              "      <td>All radioactive decay is dangerous to living t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kilauea in hawaii is the worldâ€™s most continuo...</td>\n",
              "      <td>magma</td>\n",
              "      <td>greenhouse gases</td>\n",
              "      <td>carbon and smog</td>\n",
              "      <td>smoke and ash</td>\n",
              "      <td>Example 3.5 Calculating Projectile Motion: Hot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>When a meteoroid reaches earth, what is the re...</td>\n",
              "      <td>orbit</td>\n",
              "      <td>comet</td>\n",
              "      <td>meteor</td>\n",
              "      <td>meteorite</td>\n",
              "      <td>Meteoroids are smaller than asteroids, ranging...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What kind of a reaction occurs when a substanc...</td>\n",
              "      <td>nitrogen reaction</td>\n",
              "      <td>invention reaction</td>\n",
              "      <td>Fluid Reaction</td>\n",
              "      <td>combustion reaction</td>\n",
              "      <td>A combustion reaction occurs when a substance ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Organisms categorized by what species descript...</td>\n",
              "      <td>species complex</td>\n",
              "      <td>surface species</td>\n",
              "      <td>fitting species</td>\n",
              "      <td>ring species</td>\n",
              "      <td>Ring species Ring species demonstrate a versio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Alpha emission is a type of what?</td>\n",
              "      <td>light</td>\n",
              "      <td>radiation</td>\n",
              "      <td>heat</td>\n",
              "      <td>radioactivity</td>\n",
              "      <td>One type of radioactivity is alpha emission. W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What is the stored food in a seed called?</td>\n",
              "      <td>larval</td>\n",
              "      <td>pollin</td>\n",
              "      <td>membrane</td>\n",
              "      <td>endosperm</td>\n",
              "      <td>The stored food in a seed is called endosperm ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question        distractor3  \\\n",
              "0  What type of organism is commonly used in prep...            viruses   \n",
              "1  What phenomenon makes global winds blow northe...    tropical effect   \n",
              "2  Changes from a less-ordered state to a more-or...        endothermic   \n",
              "3     What is the least dangerous radioactive decay?         zeta decay   \n",
              "4  Kilauea in hawaii is the worldâ€™s most continuo...              magma   \n",
              "5  When a meteoroid reaches earth, what is the re...              orbit   \n",
              "6  What kind of a reaction occurs when a substanc...  nitrogen reaction   \n",
              "7  Organisms categorized by what species descript...    species complex   \n",
              "8                  Alpha emission is a type of what?              light   \n",
              "9          What is the stored food in a seed called?             larval   \n",
              "\n",
              "          distractor1         distractor2        correct_answer  \\\n",
              "0            protozoa         gymnosperms  mesophilic organisms   \n",
              "1         muon effect  centrifugal effect       coriolis effect   \n",
              "2          unbalanced            reactive            exothermic   \n",
              "3          beta decay         gamma decay           alpha decay   \n",
              "4    greenhouse gases     carbon and smog         smoke and ash   \n",
              "5               comet              meteor             meteorite   \n",
              "6  invention reaction      Fluid Reaction   combustion reaction   \n",
              "7     surface species     fitting species          ring species   \n",
              "8           radiation                heat         radioactivity   \n",
              "9              pollin            membrane             endosperm   \n",
              "\n",
              "                                             support  \n",
              "0  Mesophiles grow best in moderate temperature, ...  \n",
              "1  Without Coriolis Effect the global winds would...  \n",
              "2  Summary Changes of state are examples of phase...  \n",
              "3  All radioactive decay is dangerous to living t...  \n",
              "4  Example 3.5 Calculating Projectile Motion: Hot...  \n",
              "5  Meteoroids are smaller than asteroids, ranging...  \n",
              "6  A combustion reaction occurs when a substance ...  \n",
              "7  Ring species Ring species demonstrate a versio...  \n",
              "8  One type of radioactivity is alpha emission. W...  \n",
              "9  The stored food in a seed is called endosperm ...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.to_pandas().head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T12:58:42.723610Z",
          "iopub.status.busy": "2024-02-21T12:58:42.723225Z",
          "iopub.status.idle": "2024-02-21T12:58:42.740396Z",
          "shell.execute_reply": "2024-02-21T12:58:42.739585Z",
          "shell.execute_reply.started": "2024-02-21T12:58:42.723580Z"
        },
        "id": "iUCSoaVHU4mo",
        "outputId": "530c7708-4df0-487e-96e5-8ad366438d58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "question          object\n",
              "distractor3       object\n",
              "distractor1       object\n",
              "distractor2       object\n",
              "correct_answer    object\n",
              "support           object\n",
              "dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.to_pandas().dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:01:29.005625Z",
          "iopub.status.busy": "2024-02-21T13:01:29.005232Z",
          "iopub.status.idle": "2024-02-21T13:01:29.010349Z",
          "shell.execute_reply": "2024-02-21T13:01:29.009373Z",
          "shell.execute_reply.started": "2024-02-21T13:01:29.005599Z"
        },
        "id": "KwGti9YMU4mp"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(sample):\n",
        "    full_prompt =f\"\"\"Instruct:{sample['question']}\n",
        "    \\nOutput:{sample['correct_answer']}\"\"\"\n",
        "    return {\"text\": full_prompt}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:01:30.145351Z",
          "iopub.status.busy": "2024-02-21T13:01:30.144379Z",
          "iopub.status.idle": "2024-02-21T13:01:30.151559Z",
          "shell.execute_reply": "2024-02-21T13:01:30.150628Z",
          "shell.execute_reply.started": "2024-02-21T13:01:30.145316Z"
        },
        "id": "TU2IkMMnU4mp",
        "outputId": "bf537129-8195-4796-9902-87e5a01d84b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Instruct:What phenomenon makes global winds blow northeast to southwest or the reverse in the northern hemisphere and northwest to southeast or the reverse in the southern hemisphere?\\n    \\nOutput:coriolis effect'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_prompt(train_dataset[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:02:04.483380Z",
          "iopub.status.busy": "2024-02-21T13:02:04.482524Z",
          "iopub.status.idle": "2024-02-21T13:02:04.763262Z",
          "shell.execute_reply": "2024-02-21T13:02:04.762363Z",
          "shell.execute_reply.started": "2024-02-21T13:02:04.483345Z"
        },
        "id": "QojzFIYxU4mp",
        "outputId": "77e0abd5-601e-4429-c8ae-2d387d0a5f65",
        "colab": {
          "referenced_widgets": [
            "5654833e35ec49339956309eff90fa21",
            "ef44f6f0e06c404dba45130767acbdad"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5654833e35ec49339956309eff90fa21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2336 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef44f6f0e06c404dba45130767acbdad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generated_train_dataset = train_dataset.map(\n",
        "    generate_prompt, remove_columns=list(train_dataset.features))\n",
        "generated_val_dataset = eval_dataset.map(\n",
        "    generate_prompt, remove_columns=list(eval_dataset.features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:02:09.612846Z",
          "iopub.status.busy": "2024-02-21T13:02:09.612489Z",
          "iopub.status.idle": "2024-02-21T13:02:09.619141Z",
          "shell.execute_reply": "2024-02-21T13:02:09.618242Z",
          "shell.execute_reply.started": "2024-02-21T13:02:09.612818Z"
        },
        "id": "l3o52akdU4mp",
        "outputId": "b265e951-1785-4b72-eb25-107dd8418b20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Instruct:When a meteoroid reaches earth, what is the remaining object called?\\n    \\nOutput:meteorite'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_train_dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:02:15.497001Z",
          "iopub.status.busy": "2024-02-21T13:02:15.496208Z",
          "iopub.status.idle": "2024-02-21T13:02:15.509824Z",
          "shell.execute_reply": "2024-02-21T13:02:15.508917Z",
          "shell.execute_reply.started": "2024-02-21T13:02:15.496969Z"
        },
        "id": "QJit0eywU4mp",
        "outputId": "50c2558a-3d5e-4a2f-edf8-09397d30aabb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [43993, 25, 2215, 257, 19999, 1868, 12229, 4534, 11, 644, 318, 262, 5637, 2134, 1444, 30, 198, 50284, 198, 26410, 25, 4164, 13492, 578], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(generated_train_dataset[5][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:02:26.425600Z",
          "iopub.status.busy": "2024-02-21T13:02:26.424730Z",
          "iopub.status.idle": "2024-02-21T13:02:26.506350Z",
          "shell.execute_reply": "2024-02-21T13:02:26.505423Z",
          "shell.execute_reply.started": "2024-02-21T13:02:26.425567Z"
        },
        "id": "Fd2Jp1iBU4mp"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:02:42.958508Z",
          "iopub.status.busy": "2024-02-21T13:02:42.957779Z",
          "iopub.status.idle": "2024-02-21T13:02:42.963871Z",
          "shell.execute_reply": "2024-02-21T13:02:42.962943Z",
          "shell.execute_reply.started": "2024-02-21T13:02:42.958477Z"
        },
        "id": "sEaQK-W7U4mq"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:02:47.777400Z",
          "iopub.status.busy": "2024-02-21T13:02:47.777041Z",
          "iopub.status.idle": "2024-02-21T13:02:47.782717Z",
          "shell.execute_reply": "2024-02-21T13:02:47.781812Z",
          "shell.execute_reply.started": "2024-02-21T13:02:47.777371Z"
        },
        "id": "-KDnL4hYU4mq"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:02:52.823311Z",
          "iopub.status.busy": "2024-02-21T13:02:52.822926Z",
          "iopub.status.idle": "2024-02-21T13:02:53.020206Z",
          "shell.execute_reply": "2024-02-21T13:02:53.019427Z",
          "shell.execute_reply.started": "2024-02-21T13:02:52.823282Z"
        },
        "id": "IbJn1jTfU4mq",
        "outputId": "900e5214-0772-4b12-b02e-1f55cd001fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 4362240 || all params: 1525754880 || trainable%: 0.28590699968791844\n"
          ]
        }
      ],
      "source": [
        "from peft import get_peft_model\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:03:10.563243Z",
          "iopub.status.busy": "2024-02-21T13:03:10.562534Z",
          "iopub.status.idle": "2024-02-21T13:03:10.577759Z",
          "shell.execute_reply": "2024-02-21T13:03:10.576813Z",
          "shell.execute_reply.started": "2024-02-21T13:03:10.563204Z"
        },
        "id": "P_QEi5tyU4mq",
        "outputId": "bec9e5f3-7403-497c-e7a0-d725ec7a09f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): PhiForCausalLM(\n",
              "      (model): PhiModel(\n",
              "        (embed_tokens): Embedding(51200, 2560)\n",
              "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x PhiDecoderLayer(\n",
              "            (self_attn): PhiAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "              (rotary_emb): PhiRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): PhiMLP(\n",
              "              (activation_fn): NewGELUActivation()\n",
              "              (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
              "              (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
              "            )\n",
              "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): lora.Linear(\n",
              "        (base_layer): Linear(in_features=2560, out_features=51200, bias=True)\n",
              "        (lora_dropout): ModuleDict(\n",
              "          (default): Dropout(p=0.05, inplace=False)\n",
              "        )\n",
              "        (lora_A): ModuleDict(\n",
              "          (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "        )\n",
              "        (lora_B): ModuleDict(\n",
              "          (default): Linear(in_features=8, out_features=51200, bias=False)\n",
              "        )\n",
              "        (lora_embedding_A): ParameterDict()\n",
              "        (lora_embedding_B): ParameterDict()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:03:16.821087Z",
          "iopub.status.busy": "2024-02-21T13:03:16.820418Z",
          "iopub.status.idle": "2024-02-21T13:03:16.841849Z",
          "shell.execute_reply": "2024-02-21T13:03:16.840860Z",
          "shell.execute_reply.started": "2024-02-21T13:03:16.821044Z"
        },
        "id": "wlBXf8wqU4mq"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=25,\n",
        "    logging_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    max_steps=50,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    do_eval=True,\n",
        "    report_to=\"none\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:03:22.419428Z",
          "iopub.status.busy": "2024-02-21T13:03:22.419080Z",
          "iopub.status.idle": "2024-02-21T13:03:36.113090Z",
          "shell.execute_reply": "2024-02-21T13:03:36.112108Z",
          "shell.execute_reply.started": "2024-02-21T13:03:22.419401Z"
        },
        "id": "7GYm9d0uU4mr",
        "outputId": "865d6173-3695-4d77-c9df-795c76a89375",
        "colab": {
          "referenced_widgets": [
            "612f327b359b465b9298ca12c2c954a3",
            "ef9e4d8c064d4873b4f4acb1abb363c0"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-21 13:03:25.536239: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-21 13:03:25.536345: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-21 13:03:25.693503: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:225: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "612f327b359b465b9298ca12c2c954a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2336 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef9e4d8c064d4873b4f4acb1abb363c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "# Setting sft parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    train_dataset=generated_train_dataset,\n",
        "    eval_dataset=generated_val_dataset,\n",
        "    peft_config=lora_config,\n",
        "    dataset_text_field=\"text\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:03:40.498196Z",
          "iopub.status.busy": "2024-02-21T13:03:40.497333Z",
          "iopub.status.idle": "2024-02-21T13:05:25.618151Z",
          "shell.execute_reply": "2024-02-21T13:05:25.617330Z",
          "shell.execute_reply.started": "2024-02-21T13:03:40.498166Z"
        },
        "id": "RWMmVkq3U4ms",
        "outputId": "5534d1c4-1a0a-461d-bdd5-3bab5e1beab5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 01:42, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.969500</td>\n",
              "      <td>2.208048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.087400</td>\n",
              "      <td>2.024803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50, training_loss=2.528489074707031, metrics={'train_runtime': 104.6019, 'train_samples_per_second': 1.912, 'train_steps_per_second': 0.478, 'total_flos': 102765603962880.0, 'train_loss': 2.528489074707031, 'epoch': 0.09})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config.use_cache = False\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:23:57.885606Z",
          "iopub.status.busy": "2024-02-21T13:23:57.885248Z",
          "iopub.status.idle": "2024-02-21T13:23:57.911574Z",
          "shell.execute_reply": "2024-02-21T13:23:57.910707Z",
          "shell.execute_reply.started": "2024-02-21T13:23:57.885580Z"
        },
        "id": "GwW7KOV9U4ms",
        "outputId": "10e8f173-da40-4127-f9d3-cb6fc72daefc",
        "colab": {
          "referenced_widgets": [
            "8d6163b8683248fba86eb81d3899db7e"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d6163b8683248fba86eb81d3899db7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:26:06.531033Z",
          "iopub.status.busy": "2024-02-21T13:26:06.530329Z",
          "iopub.status.idle": "2024-02-21T13:26:25.841988Z",
          "shell.execute_reply": "2024-02-21T13:26:25.840953Z",
          "shell.execute_reply.started": "2024-02-21T13:26:06.531001Z"
        },
        "id": "xcIw6fj7U4ms",
        "outputId": "23b43b87-6124-42ac-ff29-21e94daeb84b",
        "colab": {
          "referenced_widgets": [
            "cf3a30f05e344feeb8951348db1fd9a4"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf3a30f05e344feeb8951348db1fd9a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/mudogruer/Phi-2-hf-SciQ-20pc/commit/1bde94d2e2aae0d2526a2ce66051e7d4241fc647', commit_message='Upload model', commit_description='', oid='1bde94d2e2aae0d2526a2ce66051e7d4241fc647', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_finetuned_model = \"Phi-2-hf-SciQ-20pc\"\n",
        "\n",
        "trainer.model.push_to_hub(my_finetuned_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:13:41.546835Z",
          "iopub.status.busy": "2024-02-21T13:13:41.546448Z",
          "iopub.status.idle": "2024-02-21T13:13:45.899407Z",
          "shell.execute_reply": "2024-02-21T13:13:45.898582Z",
          "shell.execute_reply.started": "2024-02-21T13:13:41.546805Z"
        },
        "id": "96yM2d_DU4ms",
        "outputId": "ae223942-438a-45ac-c256-730e7a253b4b",
        "colab": {
          "referenced_widgets": [
            "ccaf7798da804aa7a4bb4099fb7cbf42"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccaf7798da804aa7a4bb4099fb7cbf42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_phi =  AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    return_dict = True,\n",
        "    load_in_4bit = True,\n",
        "    device_map = \"auto\"\n",
        ")\n",
        "config = trainer.model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:30:07.239096Z",
          "iopub.status.busy": "2024-02-21T13:30:07.238369Z",
          "iopub.status.idle": "2024-02-21T13:30:07.243523Z",
          "shell.execute_reply": "2024-02-21T13:30:07.242284Z",
          "shell.execute_reply.started": "2024-02-21T13:30:07.239064Z"
        },
        "id": "DVMEX-5HU4ms"
      },
      "outputs": [],
      "source": [
        "peft_model_id=\"mudogruer/Phi-2-hf-SciQ-20pc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:30:08.749094Z",
          "iopub.status.busy": "2024-02-21T13:30:08.748428Z",
          "iopub.status.idle": "2024-02-21T13:30:18.675300Z",
          "shell.execute_reply": "2024-02-21T13:30:18.674403Z",
          "shell.execute_reply.started": "2024-02-21T13:30:08.749059Z"
        },
        "id": "B7RkcuDTU4mt",
        "outputId": "0e261d6e-4be6-4c68-b811-a4e9ecb871a6",
        "colab": {
          "referenced_widgets": [
            "5ee692c279e6433fa44db82f633eafe8",
            "a2d579790bc847ef800d7b918fcf4af7"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ee692c279e6433fa44db82f633eafe8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/682 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2d579790bc847ef800d7b918fcf4af7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "fine_tuned_model = PeftModel.from_pretrained(\n",
        "    model_phi,\n",
        "    peft_model_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:30:40.186255Z",
          "iopub.status.busy": "2024-02-21T13:30:40.185451Z",
          "iopub.status.idle": "2024-02-21T13:30:40.202009Z",
          "shell.execute_reply": "2024-02-21T13:30:40.201062Z",
          "shell.execute_reply.started": "2024-02-21T13:30:40.186223Z"
        },
        "id": "-Cs9JGE-U4mt",
        "outputId": "063406eb-0802-4e40-9b14-01cf12aaafe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): PhiForCausalLM(\n",
              "      (model): PhiModel(\n",
              "        (embed_tokens): Embedding(51200, 2560)\n",
              "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x PhiDecoderLayer(\n",
              "            (self_attn): PhiAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "              (rotary_emb): PhiRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): PhiMLP(\n",
              "              (activation_fn): NewGELUActivation()\n",
              "              (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
              "              (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
              "            )\n",
              "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): lora.Linear(\n",
              "        (base_layer): Linear(in_features=2560, out_features=51200, bias=True)\n",
              "        (lora_dropout): ModuleDict(\n",
              "          (default): Dropout(p=0.05, inplace=False)\n",
              "        )\n",
              "        (lora_A): ModuleDict(\n",
              "          (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "        )\n",
              "        (lora_B): ModuleDict(\n",
              "          (default): Linear(in_features=8, out_features=51200, bias=False)\n",
              "        )\n",
              "        (lora_embedding_A): ParameterDict()\n",
              "        (lora_embedding_B): ParameterDict()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fine_tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:31:18.123318Z",
          "iopub.status.busy": "2024-02-21T13:31:18.122578Z",
          "iopub.status.idle": "2024-02-21T13:31:20.112884Z",
          "shell.execute_reply": "2024-02-21T13:31:20.111902Z",
          "shell.execute_reply.started": "2024-02-21T13:31:18.123271Z"
        },
        "id": "hTuzy_dyU4mt"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:31:35.045420Z",
          "iopub.status.busy": "2024-02-21T13:31:35.045044Z",
          "iopub.status.idle": "2024-02-21T13:31:35.050718Z",
          "shell.execute_reply": "2024-02-21T13:31:35.049612Z",
          "shell.execute_reply.started": "2024-02-21T13:31:35.045390Z"
        },
        "id": "xb6thragU4mt"
      },
      "outputs": [],
      "source": [
        "logging.set_verbosity(logging.CRITICAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:31:49.648395Z",
          "iopub.status.busy": "2024-02-21T13:31:49.648042Z",
          "iopub.status.idle": "2024-02-21T13:31:49.653577Z",
          "shell.execute_reply": "2024-02-21T13:31:49.652561Z",
          "shell.execute_reply.started": "2024-02-21T13:31:49.648369Z"
        },
        "id": "kP0inKHRU4mt"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    task = \"text-generation\",\n",
        "    model = fine_tuned_model,\n",
        "    tokenizer = tokenizer,\n",
        "    eos_token_id = model.config.eos_token_id,\n",
        "    max_new_tokens = 100,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:36:45.735596Z",
          "iopub.status.busy": "2024-02-21T13:36:45.734758Z",
          "iopub.status.idle": "2024-02-21T13:36:45.740332Z",
          "shell.execute_reply": "2024-02-21T13:36:45.739221Z",
          "shell.execute_reply.started": "2024-02-21T13:36:45.735565Z"
        },
        "id": "7CtZxC7sU4mt"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    task = \"text-generation\",\n",
        "    model = fine_tuned_model,\n",
        "    tokenizer = tokenizer,\n",
        "    eos_token_id = model.config.eos_token_id,\n",
        "    max_new_tokens = 30,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:36:46.815633Z",
          "iopub.status.busy": "2024-02-21T13:36:46.814779Z",
          "iopub.status.idle": "2024-02-21T13:36:49.864518Z",
          "shell.execute_reply": "2024-02-21T13:36:49.863702Z",
          "shell.execute_reply.started": "2024-02-21T13:36:46.815603Z"
        },
        "id": "iGO41S1wU4mu"
      },
      "outputs": [],
      "source": [
        "prompt = \"Which molecule in the air is the most?\"\n",
        "result = pipe(f\"<s>Instruct:{prompt}/Output:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:36:57.039206Z",
          "iopub.status.busy": "2024-02-21T13:36:57.038406Z",
          "iopub.status.idle": "2024-02-21T13:36:57.044496Z",
          "shell.execute_reply": "2024-02-21T13:36:57.043612Z",
          "shell.execute_reply.started": "2024-02-21T13:36:57.039177Z"
        },
        "id": "aZFRbrbCU4mu",
        "outputId": "54687c4d-fced-4848-cb61-e6da5ba8f04a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': '<s>InstructWhich molecule in the air is the most?/Output:Oxygen\\n    Output:Oxygen\\n    Output:Oxygen\\n    Output:Oxygen\\n    Output:Oxy'}]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:38:15.965259Z",
          "iopub.status.busy": "2024-02-21T13:38:15.964379Z",
          "iopub.status.idle": "2024-02-21T13:38:18.945392Z",
          "shell.execute_reply": "2024-02-21T13:38:18.944453Z",
          "shell.execute_reply.started": "2024-02-21T13:38:15.965224Z"
        },
        "id": "0PFLfdNsU4mu"
      },
      "outputs": [],
      "source": [
        "prompt = \"Which animal is the biggest?\"\n",
        "result = pipe(f\"<s>Instruct:{prompt}/Output:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:38:26.168599Z",
          "iopub.status.busy": "2024-02-21T13:38:26.168225Z",
          "iopub.status.idle": "2024-02-21T13:38:26.174565Z",
          "shell.execute_reply": "2024-02-21T13:38:26.173439Z",
          "shell.execute_reply.started": "2024-02-21T13:38:26.168570Z"
        },
        "id": "Ndg_WT2iU4mu",
        "outputId": "1fbefa53-658c-49dd-dbac-1ec9abdc33ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': '<s>Instruct:Which animal is the biggest?/Output:Elephant</s>\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n'}]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:45:25.978153Z",
          "iopub.status.busy": "2024-02-21T13:45:25.977329Z",
          "iopub.status.idle": "2024-02-21T13:45:46.038784Z",
          "shell.execute_reply": "2024-02-21T13:45:46.037833Z",
          "shell.execute_reply.started": "2024-02-21T13:45:25.978123Z"
        },
        "id": "YkaVjrLlU4mu",
        "outputId": "0e4700f1-3012-4901-fbdd-d6735ded511a",
        "colab": {
          "referenced_widgets": [
            "98f355da74d6492b958b99de3d09d56d"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98f355da74d6492b958b99de3d09d56d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/mudogruer/Sciq-Phi-20pc/commit/385f12dba78f9aeec2fe9ff43a58c6f9d9c0e817', commit_message='Upload model', commit_description='', oid='385f12dba78f9aeec2fe9ff43a58c6f9d9c0e817', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fused_model = \"Sciq-Phi-20pc\"\n",
        "\n",
        "trainer.model.push_to_hub(fused_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:44:57.459786Z",
          "iopub.status.busy": "2024-02-21T13:44:57.459428Z",
          "iopub.status.idle": "2024-02-21T13:44:57.476817Z",
          "shell.execute_reply": "2024-02-21T13:44:57.475884Z",
          "shell.execute_reply.started": "2024-02-21T13:44:57.459758Z"
        },
        "id": "aGnEt3I1U4mu",
        "outputId": "e814be06-7175-4634-b99b-f9f7dfd3ee82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): PhiForCausalLM(\n",
              "      (model): PhiModel(\n",
              "        (embed_tokens): Embedding(51200, 2560)\n",
              "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x PhiDecoderLayer(\n",
              "            (self_attn): PhiAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "              (rotary_emb): PhiRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): PhiMLP(\n",
              "              (activation_fn): NewGELUActivation()\n",
              "              (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
              "              (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
              "            )\n",
              "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): lora.Linear(\n",
              "        (base_layer): Linear(in_features=2560, out_features=51200, bias=True)\n",
              "        (lora_dropout): ModuleDict(\n",
              "          (default): Dropout(p=0.05, inplace=False)\n",
              "        )\n",
              "        (lora_A): ModuleDict(\n",
              "          (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "        )\n",
              "        (lora_B): ModuleDict(\n",
              "          (default): Linear(in_features=8, out_features=51200, bias=False)\n",
              "        )\n",
              "        (lora_embedding_A): ParameterDict()\n",
              "        (lora_embedding_B): ParameterDict()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fine_tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-21T13:52:18.559163Z",
          "iopub.status.busy": "2024-02-21T13:52:18.558772Z",
          "iopub.status.idle": "2024-02-21T13:52:28.278030Z",
          "shell.execute_reply": "2024-02-21T13:52:28.277055Z",
          "shell.execute_reply.started": "2024-02-21T13:52:18.559134Z"
        },
        "id": "5L97xwVNU4mv",
        "outputId": "9379bbd6-a2f8-4cca-c33b-acc8bef6377c",
        "colab": {
          "referenced_widgets": [
            "6099aa4fd9a441c5bd5b501cd80e2e16"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:134: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6099aa4fd9a441c5bd5b501cd80e2e16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/279M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/mudogruer/Sciq-Phi-20pc/commit/b064209b9e159435fafa8b91ee4ad828866102bb', commit_message='Upload model', commit_description='', oid='b064209b9e159435fafa8b91ee4ad828866102bb', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fine_tuned_model.push_to_hub(fused_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6id3pcUU4mv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}